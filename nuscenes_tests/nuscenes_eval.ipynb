{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4b6b74-9e15-4b62-afd7-47062c26ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This file is currently under development. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3635b65f-614a-4040-8271-1c07bae6ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install nuscenes-devkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "527b2462-b804-44ed-a305-1a5617c39b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.utils.data_classes import RadarPointCloud\n",
    "from nuscenes.eval.detection.evaluate import NuScenesEval\n",
    "from nuscenes.eval.detection.data_classes import DetectionConfig\n",
    "from nuscenes.eval.prediction.splits import get_prediction_challenge_split\n",
    "from nuscenes.prediction import PredictHelper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aadd00-73a5-4614-b708-1073954b7357",
   "metadata": {},
   "source": [
    "## Load Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b74b868f-3817-410c-a65c-25921425eeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt to 'weights/yolo11m.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 38.8M/38.8M [00:03<00:00, 11.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('weights/yolo11m.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04d50eaf-476e-4f36-93a8-d07995a8a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAROOT = '../data/nuscenes_full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff076cdc-2040-42cf-ba5f-4a5af0e1c831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 22.328 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 5.4 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "nusc = NuScenes(version='v1.0-trainval', dataroot=DATAROOT, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fd0feb4-7cf5-46bc-a003-d43925b413a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = PredictHelper(nusc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15018508-a033-46fb-8a75-2a5a0b7b76c5",
   "metadata": {},
   "source": [
    "## Perform Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9296997a-96c4-4d09-bae2-82022e0a8e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "IOU_THRESHOLD = 0.6\n",
    "CONFIDENCE_THRESHOLD = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60ce2529-9ec5-4571-b5ec-5df71254fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_INDEX = 0\n",
    "END_INDEX = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37e0e51f-8b00-46a7-8fad-d404b4c4f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'CAM_FRONT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9ebe2b88-a509-40b3-9623-6c0b20f25089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/012392471@SJSUAD/master_project/nuscenes_tests/../data/nuscenes_full/samples/CAM_FRONT/n015-2018-07-18-11-07-57+0800__CAM_FRONT__1531883530412470.jpg: 384x640 1 person, 1 truck, 2 traffic lights, 124.1ms\n",
      "Speed: 1.2ms preprocess, 124.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "===================================================\n",
      "\n",
      "image 1/1 /home/012392471@SJSUAD/master_project/nuscenes_tests/../data/nuscenes_full/samples/CAM_FRONT/n015-2018-07-18-11-07-57+0800__CAM_FRONT__1531883719412465.jpg: 384x640 4 cars, 1 truck, 2 traffic lights, 123.2ms\n",
      "Speed: 1.2ms preprocess, 123.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "===================================================\n",
      "\n",
      "image 1/1 /home/012392471@SJSUAD/master_project/nuscenes_tests/../data/nuscenes_full/samples/CAM_FRONT/n015-2018-08-02-17-16-37+0800__CAM_FRONT__1533201470412460.jpg: 384x640 1 car, 124.4ms\n",
      "Speed: 1.2ms preprocess, 124.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "===================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(START_INDEX, END_INDEX):\n",
    "    test_scene = nusc.scene[i]\n",
    "    first_sample_token = test_scene['first_sample_token']\n",
    "    my_sample = nusc.get('sample', first_sample_token)\n",
    "    cam_front_data = nusc.get('sample_data', my_sample['data'][sensor])\n",
    "\n",
    "    radar_front_data = nusc.get('sample_data', my_sample['data']['RADAR_FRONT'])\n",
    "    pc = RadarPointCloud.from_file(os.path.join(DATAROOT, radar_front_data[\"filename\"]))\n",
    "    data = pc.points.astype(dtype=np.float32).T\n",
    "\n",
    "    image_path = os.path.join(nusc.dataroot, cam_front_data['filename'])\n",
    "    results = model(image_path, conf=CONFIDENCE_THRESHOLD, iou=IOU_THRESHOLD)\n",
    "\n",
    "    # dict_key = f\"sample_token_{i+1}\"\n",
    "    dict_key = f\"{first_sample_token}\"\n",
    "    arr = []\n",
    "    \n",
    "    for (object_index, box) in enumerate(results[0].boxes):\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy.tolist()[0])\n",
    "        class_id = int(box.cls)\n",
    "        class_name = results[0].names[class_id]\n",
    "        confidence = box.conf.item()\n",
    "        \n",
    "        my_annotation_token = my_sample['anns'][object_index]\n",
    "        my_annotation_metadata =  nusc.get('sample_annotation', my_annotation_token)\n",
    "\n",
    "        attr_tokens = my_annotation_metadata['attribute_tokens']\n",
    "        if(len(attr_tokens) == 0):\n",
    "            name = \"\"\n",
    "        else:\n",
    "            attr = nusc.get('attribute', attr_tokens[0])['name']\n",
    "            name = attr.split('.')[0]\n",
    "\n",
    "        instance_token = my_annotation_metadata[\"instance_token\"]\n",
    "        instance = nusc.get('instance', instance_token)\n",
    "        category = nusc.get('category', instance['category_token'])\n",
    "        detection_name = category[\"name\"].split('.')[1]\n",
    "\n",
    "        if detection_name == \"trafficcone\":\n",
    "            detection_name = \"traffic_cone\"\n",
    "        \n",
    "        prediction_object = {\n",
    "            'sample_token': first_sample_token,\n",
    "            'translation': [],  # Center of 3D box\n",
    "            'size': [],  # Dimensions of 3D box\n",
    "            'rotation': [],  # Rotation as quaternion\n",
    "            'velocity': [],\n",
    "            'detection_name': detection_name,  # e.g., 'car', 'pedestrian'\n",
    "            'detection_score': confidence,  # Between 0 and 1\n",
    "            'attribute_name': attr\n",
    "        }\n",
    "\n",
    "        arr.append(prediction_object)\n",
    "\n",
    "    prediction_results[\"results\"][dict_key] = arr\n",
    "\n",
    "    print(\"===================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16f14225-be9c-4fb5-be0a-1bbae019fbe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta': {'use_camera': True,\n",
       "  'use_lidar': False,\n",
       "  'use_radar': False,\n",
       "  'use_map': False,\n",
       "  'use_external': False},\n",
       " 'results': {'fd8420396768425eabec9bdddf7e64b6': [{'sample_token': 'fd8420396768425eabec9bdddf7e64b6',\n",
       "    'translation': [242.87, 926.036, 0.898],\n",
       "    'size': [1.726, 4.257, 1.489],\n",
       "    'rotation': [0.787419398050721, 0.0, 0.0, -0.616417627565468],\n",
       "    'velocity': [0.25, 0.13633444905281067],\n",
       "    'detection_name': 'car',\n",
       "    'detection_score': 0.9393414855003357,\n",
       "    'attribute_name': 'vehicle.moving'}],\n",
       "  'e93e98b63d3b40209056d129dc53ceee': [{'sample_token': 'e93e98b63d3b40209056d129dc53ceee',\n",
       "    'translation': [994.031, 612.51, 0.728],\n",
       "    'size': [0.3, 0.291, 0.734],\n",
       "    'rotation': [-0.04208490861058176, 0.0, 0.0, 0.9991140377690821],\n",
       "    'velocity': [-3.5, -0.017412938177585602],\n",
       "    'detection_name': 'traffic_cone',\n",
       "    'detection_score': 0.8136498332023621,\n",
       "    'attribute_name': 'vehicle.moving'},\n",
       "   {'sample_token': 'e93e98b63d3b40209056d129dc53ceee',\n",
       "    'translation': [994.381, 609.33, 0.667],\n",
       "    'size': [0.315, 0.338, 0.712],\n",
       "    'rotation': [-0.09426469466835254, 0.0, 0.0, 0.9955471698212407],\n",
       "    'velocity': [-3.0, -0.023164520040154457],\n",
       "    'detection_name': 'traffic_cone',\n",
       "    'detection_score': 0.6829022765159607,\n",
       "    'attribute_name': 'vehicle.moving'},\n",
       "   {'sample_token': 'e93e98b63d3b40209056d129dc53ceee',\n",
       "    'translation': [1002.464, 632.267, 1.936],\n",
       "    'size': [2.312, 7.516, 3.093],\n",
       "    'rotation': [0.9343569321017062, 0.0, 0.0, -0.35633849558178193],\n",
       "    'velocity': [-3.75, 0.018140055239200592],\n",
       "    'detection_name': 'truck',\n",
       "    'detection_score': 0.6137102842330933,\n",
       "    'attribute_name': 'vehicle.parked'},\n",
       "   {'sample_token': 'e93e98b63d3b40209056d129dc53ceee',\n",
       "    'translation': [1018.705, 605.045, 0.731],\n",
       "    'size': [1.638, 4.25, 1.44],\n",
       "    'rotation': [0.9930201651831624, 0.0, 0.0, 0.11794469695414371],\n",
       "    'velocity': [-5.25, -0.009272357448935509],\n",
       "    'detection_name': 'car',\n",
       "    'detection_score': 0.6113307476043701,\n",
       "    'attribute_name': 'vehicle.moving'}],\n",
       "  '9e28820bd2ba4eb480e1b9079f17c30c': [{'sample_token': '9e28820bd2ba4eb480e1b9079f17c30c',\n",
       "    'translation': [360.441, 1105.96, 0.843],\n",
       "    'size': [0.429, 0.339, 1.711],\n",
       "    'rotation': [0.9913168135808315, 0.0, 0.0, -0.13149515242755913],\n",
       "    'velocity': [-0.75, 0.05905528739094734],\n",
       "    'detection_name': 'pedestrian',\n",
       "    'detection_score': 0.863028883934021,\n",
       "    'attribute_name': 'pedestrian.standing'},\n",
       "   {'sample_token': '9e28820bd2ba4eb480e1b9079f17c30c',\n",
       "    'translation': [395.527, 1104.206, 0.427],\n",
       "    'size': [2.114, 0.351, 0.996],\n",
       "    'rotation': [0.8398378410784267, 0.0, 0.0, 0.5428373611798724],\n",
       "    'velocity': [-0.75, 0.045153580605983734],\n",
       "    'detection_name': 'barrier',\n",
       "    'detection_score': 0.8226322531700134,\n",
       "    'attribute_name': 'pedestrian.standing'},\n",
       "   {'sample_token': '9e28820bd2ba4eb480e1b9079f17c30c',\n",
       "    'translation': [352.709, 1068.677, 1.398],\n",
       "    'size': [1.945, 4.94, 2.734],\n",
       "    'rotation': [0.8342998112464631, 0.0, 0.0, 0.5513110056529944],\n",
       "    'velocity': [-1.75, -0.021606331691145897],\n",
       "    'detection_name': 'truck',\n",
       "    'detection_score': 0.6816037893295288,\n",
       "    'attribute_name': 'vehicle.parked'},\n",
       "   {'sample_token': '9e28820bd2ba4eb480e1b9079f17c30c',\n",
       "    'translation': [361.486, 1094.462, 0.266],\n",
       "    'size': [2.115, 0.36, 1.024],\n",
       "    'rotation': [0.2664562267582201, 0.0, 0.0, 0.9638470206530557],\n",
       "    'velocity': [-1.75, 0.07368971407413483],\n",
       "    'detection_name': 'barrier',\n",
       "    'detection_score': 0.6714577674865723,\n",
       "    'attribute_name': 'vehicle.parked'},\n",
       "   {'sample_token': '9e28820bd2ba4eb480e1b9079f17c30c',\n",
       "    'translation': [363.199, 1128.181, 1.334],\n",
       "    'size': [1.802, 4.744, 2.0],\n",
       "    'rotation': [0.9796996478126853, 0.0, 0.0, -0.20047094571458607],\n",
       "    'velocity': [-2.0, 0.05157526955008507],\n",
       "    'detection_name': 'car',\n",
       "    'detection_score': 0.6116938591003418,\n",
       "    'attribute_name': 'vehicle.moving'},\n",
       "   {'sample_token': '9e28820bd2ba4eb480e1b9079f17c30c',\n",
       "    'translation': [390.248, 1107.822, 0.498],\n",
       "    'size': [2.106, 0.364, 0.998],\n",
       "    'rotation': [0.9760194511579651, 0.0, 0.0, 0.21768332724695416],\n",
       "    'velocity': [-1.75, 0.022597026079893112],\n",
       "    'detection_name': 'barrier',\n",
       "    'detection_score': 0.488715261220932,\n",
       "    'attribute_name': 'vehicle.moving'},\n",
       "   {'sample_token': '9e28820bd2ba4eb480e1b9079f17c30c',\n",
       "    'translation': [356.499, 1082.918, 0.2],\n",
       "    'size': [2.203, 0.358, 1.009],\n",
       "    'rotation': [0.20163353519082008, 0.0, 0.0, 0.9794610341848482],\n",
       "    'velocity': [-2.0, -0.025214049965143204],\n",
       "    'detection_name': 'barrier',\n",
       "    'detection_score': 0.47955378890037537,\n",
       "    'attribute_name': 'vehicle.moving'}]}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a609bc3-d95b-44a7-9356-0bb703f07e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.json', 'w') as fp:\n",
    "    json.dump(prediction_results, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbecf8b9-5518-4314-b753-442592484fe5",
   "metadata": {},
   "source": [
    "## Perform Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd15ba21-15c4-47d7-8982-ecde21960c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('detection_cvpr_2019.json', 'r') as fp:\n",
    "    config_str = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "14b4d572-f85c-4f0f-b1c8-56699ab99fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_config = DetectionConfig(\n",
    "    class_range = config_str[\"class_range\"],\n",
    "    dist_fcn = config_str[\"dist_fcn\"],\n",
    "    dist_ths = config_str[\"dist_ths\"],\n",
    "    dist_th_tp = config_str[\"dist_th_tp\"],\n",
    "    min_recall = config_str[\"min_recall\"],\n",
    "    min_precision = config_str[\"min_precision\"],\n",
    "    max_boxes_per_sample = config_str[\"max_boxes_per_sample\"],\n",
    "    mean_ap_weight = config_str[\"mean_ap_weight\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4b8a85e-464b-4010-869d-5d785ea5e523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot notation didn't work because you can't use dot \n",
    "#    on dictionaries only objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ddc3f885-027c-4c15-8857-dfed83cd01fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing nuScenes detection evaluation\n",
      "Loaded results from results.json. Found detections for 3 samples.\n",
      "Loading annotations for val split from nuScenes version: v1.0-trainval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 6019/6019 [00:07<00:00, 813.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ground truth annotations for 6019 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Samples in split doesn't match samples in predictions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m \u001b[43mNuScenesEval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnusc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetection_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                         \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mresult_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresults.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                         \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutputs/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nuscenes/eval/detection/evaluate.py:84\u001b[0m, in \u001b[0;36mDetectionEval.__init__\u001b[0;34m(self, nusc, config, result_path, eval_set, output_dir, verbose)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_boxes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta \u001b[38;5;241m=\u001b[39m load_prediction(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmax_boxes_per_sample, DetectionBox,\n\u001b[1;32m     81\u001b[0m                                              verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgt_boxes \u001b[38;5;241m=\u001b[39m load_gt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnusc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_set, DetectionBox, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_boxes\u001b[38;5;241m.\u001b[39msample_tokens) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgt_boxes\u001b[38;5;241m.\u001b[39msample_tokens), \\\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSamples in split doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match samples in predictions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Add center distances.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_boxes \u001b[38;5;241m=\u001b[39m add_center_dist(nusc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_boxes)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Samples in split doesn't match samples in predictions."
     ]
    }
   ],
   "source": [
    "evaluator = NuScenesEval(nusc,\n",
    "                         config=detection_config,\n",
    "                         eval_set='val',\n",
    "                         result_path=\"results.json\",\n",
    "                         output_dir='outputs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd78ffa8-f096-4664-87fe-f38ee196b53b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
